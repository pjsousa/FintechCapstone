{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1070 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser as dtparser\n",
    "\n",
    "from utils.datafetch import *\n",
    "from utils.vectorized_funs import *\n",
    "from utils.datapipe import *\n",
    "from utils.kerasutil import *\n",
    "from utils import scenarioa\n",
    "from FintechCapstone import FinCapstone\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/3) Recv. and Stored GLW\n",
      "(2/3) Recv. and Stored HIMX\n",
      "(3/3) Recv. and Stored GLUU\n",
      "Took 0:00:02.656143\n",
      "\n",
      "\n",
      " - GLW - \n",
      "\n",
      "\n",
      "\n",
      " - HIMX - \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "date_from = '2009-01-01'\n",
    "date_to = '2017-03-01'\n",
    "timespan = {\n",
    "    \"short_term\": [1, 5]\n",
    "    ,\"medium_term\": [40]\n",
    "    ,\"long_term\": [90]\n",
    "}\n",
    "\n",
    "trial = FinCapstone(ticker_list=[\"GLW\",\"HIMX\",\"GLUU\"], ticker_list_samplesize=4, timespan=timespan, date_from=date_from)\n",
    "#trial = FinCapstone(ticker_list=[\"ZHNE\",\"BSFT\",\"AERO\",\"MATR\",\"ITMSF\",\"FIT\",\"TIPT\",\"OLBK\",\"QADA\",\"ATTU\",\"LGF\",\"STX\",\"TPCS\",\"GSAT\",\"ZNGA\",\"GLW\",\"HIMX\",\"YHOO\", \"NWSA\",\"JAKK\",\"GLUU\",\"AMZN\", \"AAPL\", \"EBAY\", \"GOOG\", \"DIS\", \"NFLX\", \"EA\", \"TWTR\", \"FB\", \"TTWO\", \"PXLW\", \"UBI\"], ticker_list_samplesize=4, timespan=timespan, timespan_ab=timespan_ab, date_from=date_from)\n",
    "#trial = FinCapstone(ticker_list_samplesize=200, timespan=timespan, timespan_ab=timespan_ab, date_from=date_from)\n",
    "\n",
    "trial.run_initial_dataload()\n",
    "trial.feature_engineering(feature_set=\"scenarioa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = trial.load_scenarioa_features(\"GLUU\", True)\n",
    "y = trial.load_scenarioa_labels(\"GLUU\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features_df = trial.load_scenarioa_features(\"GLUU\", parseDate=True)\n",
    "features_df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "labels_df = trial.load_scenarioa_labels(\"GLUU\", parseDate=True)\n",
    "labels_df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "model = scenarioa.create_model()\n",
    "X_train, y_train, X_test, y_test = scenarioa.prepare_problemspace(\"GLUU\", trial.valid_ticker_list(), trial.train_from, trial.train_until, trial.test_from)\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = scenarioa.prepare_problemspace(\"GLUU\", trial.valid_ticker_list(), trial.train_from, trial.train_until, trial.test_from, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = scenarioa.prepare_problemspace(\"GLUU\", trial.valid_ticker_list(), trial.train_from, trial.train_until, trial.test_from, \"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "('Error allocating 226492416 bytes of device memory (out of memory).', \"you might consider using 'theano.shared(..., borrow=True)'\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-6790ec0c7c74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscenarioa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/pedro/jupyternb/FintechCapstone/utils/scenarioa.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mkutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFCBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_batchnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mkutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFCBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_batchnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mkutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFCBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_batchnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pedro/jupyternb/FintechCapstone/utils/kerasutil.py\u001b[0m in \u001b[0;36mFCBlock\u001b[0;34m(model, add_batchnorm, add_dropout)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pedro/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    330\u001b[0m                  output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/home/pedro/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    544\u001b[0m                                      '`layer.build(batch_input_shape)`')\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pedro/anaconda3/lib/python3.5/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    796\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{}_W'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                  \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                                  constraint=self.W_constraint)\n\u001b[0m\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             self.b = self.add_weight((self.output_dim,),\n",
      "\u001b[0;32m/home/pedro/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, shape, initializer, name, trainable, regularizer, constraint)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \"\"\"\n\u001b[1;32m    417\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pedro/anaconda3/lib/python3.5/site-packages/keras/initializations.py\u001b[0m in \u001b[0;36mglorot_uniform\u001b[0;34m(shape, name, dim_ordering)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfan_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_ordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim_ordering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfan_in\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pedro/anaconda3/lib/python3.5/site-packages/keras/initializations.py\u001b[0m in \u001b[0;36muniform\u001b[0;34m(shape, scale, name, dim_ordering)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_ordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'th'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pedro/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36mrandom_uniform_variable\u001b[0;34m(shape, low, high, dtype, name)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrandom_uniform_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     return variable(np.random.uniform(low=low, high=high, size=shape),\n\u001b[0;32m--> 189\u001b[0;31m                     dtype=dtype, name=name)\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pedro/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(value, dtype, name)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pedro/anaconda3/lib/python3.5/site-packages/theano/compile/sharedvalue.py\u001b[0m in \u001b[0;36mshared\u001b[0;34m(value, name, strict, allow_downcast, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 var = ctor(value, name=name, strict=strict,\n\u001b[0;32m--> 268\u001b[0;31m                            allow_downcast=allow_downcast, **kwargs)\n\u001b[0m\u001b[1;32m    269\u001b[0m                 \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_tag_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pedro/anaconda3/lib/python3.5/site-packages/theano/sandbox/cuda/var.py\u001b[0m in \u001b[0;36mfloat32_shared_constructor\u001b[0;34m(value, name, strict, allow_downcast, borrow, broadcastable, target)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# type.broadcastable is guaranteed to be a tuple, which this next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# function requires\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mdeviceval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_support_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcastable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: ('Error allocating 226492416 bytes of device memory (out of memory).', \"you might consider using 'theano.shared(..., borrow=True)'\")"
     ]
    }
   ],
   "source": [
    "model = scenarioa.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = scenarioa.prepare_problemspace(\"GLUU\", trial.valid_ticker_list(), trial.train_from, trial.train_until, trial.test_from, \"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1510/1510 [==============================] - 4s - loss: nan     \n",
      "Epoch 2/2\n",
      "1510/1510 [==============================] - 4s - loss: nan     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7f8a922736a0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarioa.fit(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.core.panel.Panel'>\n",
       "Dimensions: 1510 (items) x 29 (major_axis) x 3 (minor_axis)\n",
       "Items axis: 2010-01-04 00:00:00 to 2015-12-31 00:00:00\n",
       "Major_axis axis: Close to OBV\n",
       "Minor_axis axis: GLUU to HIMX"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RETURN_1</th>\n",
       "      <th>RETURN_30</th>\n",
       "      <th>RETURN_60</th>\n",
       "      <th>RETURN_200</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>0.049587</td>\n",
       "      <td>-0.132231</td>\n",
       "      <td>-0.190083</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.181102</td>\n",
       "      <td>-0.212598</td>\n",
       "      <td>0.322835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>0.031496</td>\n",
       "      <td>-0.188976</td>\n",
       "      <td>-0.212598</td>\n",
       "      <td>0.393701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>0.106870</td>\n",
       "      <td>-0.259542</td>\n",
       "      <td>-0.206107</td>\n",
       "      <td>0.343511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>-0.013793</td>\n",
       "      <td>-0.365517</td>\n",
       "      <td>-0.275862</td>\n",
       "      <td>0.151724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>-0.034965</td>\n",
       "      <td>-0.349650</td>\n",
       "      <td>-0.307692</td>\n",
       "      <td>0.188811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-12</th>\n",
       "      <td>-0.014493</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.275362</td>\n",
       "      <td>0.231884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-13</th>\n",
       "      <td>0.051471</td>\n",
       "      <td>-0.323529</td>\n",
       "      <td>-0.139706</td>\n",
       "      <td>0.257353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-14</th>\n",
       "      <td>0.006993</td>\n",
       "      <td>-0.356643</td>\n",
       "      <td>-0.167832</td>\n",
       "      <td>0.195804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-15</th>\n",
       "      <td>-0.041667</td>\n",
       "      <td>-0.368056</td>\n",
       "      <td>-0.173611</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-19</th>\n",
       "      <td>0.043478</td>\n",
       "      <td>-0.384058</td>\n",
       "      <td>-0.195652</td>\n",
       "      <td>0.159420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-20</th>\n",
       "      <td>0.020833</td>\n",
       "      <td>-0.381944</td>\n",
       "      <td>-0.284722</td>\n",
       "      <td>0.131944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-21</th>\n",
       "      <td>-0.020408</td>\n",
       "      <td>-0.380952</td>\n",
       "      <td>-0.312925</td>\n",
       "      <td>0.183673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-22</th>\n",
       "      <td>0.006944</td>\n",
       "      <td>-0.354167</td>\n",
       "      <td>-0.298611</td>\n",
       "      <td>0.201389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-25</th>\n",
       "      <td>-0.034483</td>\n",
       "      <td>-0.324138</td>\n",
       "      <td>-0.282759</td>\n",
       "      <td>0.165517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-26</th>\n",
       "      <td>0.021429</td>\n",
       "      <td>-0.264286</td>\n",
       "      <td>-0.221429</td>\n",
       "      <td>0.307143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-27</th>\n",
       "      <td>-0.006993</td>\n",
       "      <td>-0.286713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-28</th>\n",
       "      <td>0.028169</td>\n",
       "      <td>-0.316901</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>0.697183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-29</th>\n",
       "      <td>-0.041096</td>\n",
       "      <td>-0.342466</td>\n",
       "      <td>0.061644</td>\n",
       "      <td>0.589041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-02</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.307143</td>\n",
       "      <td>-0.085714</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-03</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-04</th>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-05</th>\n",
       "      <td>0.015385</td>\n",
       "      <td>-0.230769</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>0.707692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-08</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.719697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-09</th>\n",
       "      <td>-0.053030</td>\n",
       "      <td>-0.242424</td>\n",
       "      <td>-0.068182</td>\n",
       "      <td>0.651515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-10</th>\n",
       "      <td>-0.152000</td>\n",
       "      <td>-0.192000</td>\n",
       "      <td>-0.008000</td>\n",
       "      <td>0.768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-11</th>\n",
       "      <td>-0.009434</td>\n",
       "      <td>-0.056604</td>\n",
       "      <td>0.198113</td>\n",
       "      <td>1.216981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-12</th>\n",
       "      <td>0.028571</td>\n",
       "      <td>-0.047619</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>1.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-16</th>\n",
       "      <td>-0.027778</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.268519</td>\n",
       "      <td>1.046296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-18</th>\n",
       "      <td>-0.026946</td>\n",
       "      <td>-0.275449</td>\n",
       "      <td>0.071856</td>\n",
       "      <td>-0.299401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-19</th>\n",
       "      <td>0.012308</td>\n",
       "      <td>-0.264615</td>\n",
       "      <td>0.150769</td>\n",
       "      <td>-0.292308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-20</th>\n",
       "      <td>0.006079</td>\n",
       "      <td>-0.288754</td>\n",
       "      <td>0.185410</td>\n",
       "      <td>-0.291793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.338369</td>\n",
       "      <td>0.141994</td>\n",
       "      <td>-0.311178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-24</th>\n",
       "      <td>0.024169</td>\n",
       "      <td>-0.271903</td>\n",
       "      <td>0.120846</td>\n",
       "      <td>-0.308157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-25</th>\n",
       "      <td>0.011799</td>\n",
       "      <td>-0.274336</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>-0.330383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-27</th>\n",
       "      <td>-0.014577</td>\n",
       "      <td>-0.349854</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.364431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-30</th>\n",
       "      <td>-0.050296</td>\n",
       "      <td>-0.372781</td>\n",
       "      <td>0.136095</td>\n",
       "      <td>-0.346154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-01</th>\n",
       "      <td>-0.021807</td>\n",
       "      <td>-0.317757</td>\n",
       "      <td>0.155763</td>\n",
       "      <td>-0.308411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-02</th>\n",
       "      <td>-0.019108</td>\n",
       "      <td>-0.305732</td>\n",
       "      <td>0.057325</td>\n",
       "      <td>-0.299363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-03</th>\n",
       "      <td>-0.025974</td>\n",
       "      <td>-0.262987</td>\n",
       "      <td>0.100649</td>\n",
       "      <td>-0.295455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-04</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.260000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-07</th>\n",
       "      <td>-0.009901</td>\n",
       "      <td>-0.270627</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>-0.270627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-08</th>\n",
       "      <td>-0.026667</td>\n",
       "      <td>-0.206667</td>\n",
       "      <td>0.063333</td>\n",
       "      <td>-0.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-09</th>\n",
       "      <td>0.003425</td>\n",
       "      <td>-0.212329</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-10</th>\n",
       "      <td>-0.047782</td>\n",
       "      <td>-0.215017</td>\n",
       "      <td>0.061433</td>\n",
       "      <td>-0.242321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-11</th>\n",
       "      <td>0.028674</td>\n",
       "      <td>-0.182796</td>\n",
       "      <td>0.103943</td>\n",
       "      <td>-0.204301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-14</th>\n",
       "      <td>0.045296</td>\n",
       "      <td>-0.233449</td>\n",
       "      <td>0.128920</td>\n",
       "      <td>-0.240418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-15</th>\n",
       "      <td>0.046667</td>\n",
       "      <td>-0.263333</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>-0.253333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>-0.050955</td>\n",
       "      <td>-0.299363</td>\n",
       "      <td>-0.028662</td>\n",
       "      <td>-0.296178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-17</th>\n",
       "      <td>-0.010067</td>\n",
       "      <td>-0.305369</td>\n",
       "      <td>0.050336</td>\n",
       "      <td>-0.261745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-18</th>\n",
       "      <td>-0.193220</td>\n",
       "      <td>-0.318644</td>\n",
       "      <td>0.064407</td>\n",
       "      <td>-0.244068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-21</th>\n",
       "      <td>-0.063025</td>\n",
       "      <td>0.121849</td>\n",
       "      <td>0.327731</td>\n",
       "      <td>-0.063025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-22</th>\n",
       "      <td>0.125561</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.376682</td>\n",
       "      <td>-0.017937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-23</th>\n",
       "      <td>-0.003984</td>\n",
       "      <td>0.075697</td>\n",
       "      <td>0.227092</td>\n",
       "      <td>-0.131474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-24</th>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>-0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-28</th>\n",
       "      <td>-0.003984</td>\n",
       "      <td>0.207171</td>\n",
       "      <td>0.167331</td>\n",
       "      <td>-0.159363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-29</th>\n",
       "      <td>-0.004000</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>-0.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-30</th>\n",
       "      <td>-0.024096</td>\n",
       "      <td>0.269076</td>\n",
       "      <td>0.128514</td>\n",
       "      <td>-0.180723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>-0.004115</td>\n",
       "      <td>0.390947</td>\n",
       "      <td>0.152263</td>\n",
       "      <td>-0.168724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1510 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            RETURN_1  RETURN_30  RETURN_60  RETURN_200\n",
       "Date                                                  \n",
       "2010-01-04  0.049587  -0.132231  -0.190083    0.363636\n",
       "2010-01-05  0.000000  -0.181102  -0.212598    0.322835\n",
       "2010-01-06  0.031496  -0.188976  -0.212598    0.393701\n",
       "2010-01-07  0.106870  -0.259542  -0.206107    0.343511\n",
       "2010-01-08 -0.013793  -0.365517  -0.275862    0.151724\n",
       "2010-01-11 -0.034965  -0.349650  -0.307692    0.188811\n",
       "2010-01-12 -0.014493  -0.333333  -0.275362    0.231884\n",
       "2010-01-13  0.051471  -0.323529  -0.139706    0.257353\n",
       "2010-01-14  0.006993  -0.356643  -0.167832    0.195804\n",
       "2010-01-15 -0.041667  -0.368056  -0.173611    0.187500\n",
       "2010-01-19  0.043478  -0.384058  -0.195652    0.159420\n",
       "2010-01-20  0.020833  -0.381944  -0.284722    0.131944\n",
       "2010-01-21 -0.020408  -0.380952  -0.312925    0.183673\n",
       "2010-01-22  0.006944  -0.354167  -0.298611    0.201389\n",
       "2010-01-25 -0.034483  -0.324138  -0.282759    0.165517\n",
       "2010-01-26  0.021429  -0.264286  -0.221429    0.307143\n",
       "2010-01-27 -0.006993  -0.286713   0.000000    0.566434\n",
       "2010-01-28  0.028169  -0.316901   0.169014    0.697183\n",
       "2010-01-29 -0.041096  -0.342466   0.061644    0.589041\n",
       "2010-02-01  0.000000  -0.300000   0.000000    0.614286\n",
       "2010-02-02  0.000000  -0.307143  -0.085714    0.500000\n",
       "2010-02-03  0.000000  -0.285714   0.107143    0.657143\n",
       "2010-02-04 -0.071429  -0.285714   0.028571    0.642857\n",
       "2010-02-05  0.015385  -0.230769   0.069231    0.707692\n",
       "2010-02-08  0.000000  -0.250000   0.022727    0.719697\n",
       "2010-02-09 -0.053030  -0.242424  -0.068182    0.651515\n",
       "2010-02-10 -0.152000  -0.192000  -0.008000    0.768000\n",
       "2010-02-11 -0.009434  -0.056604   0.198113    1.216981\n",
       "2010-02-12  0.028571  -0.047619   0.314286    1.142857\n",
       "2010-02-16 -0.027778  -0.083333   0.268519    1.046296\n",
       "...              ...        ...        ...         ...\n",
       "2015-11-18 -0.026946  -0.275449   0.071856   -0.299401\n",
       "2015-11-19  0.012308  -0.264615   0.150769   -0.292308\n",
       "2015-11-20  0.006079  -0.288754   0.185410   -0.291793\n",
       "2015-11-23  0.000000  -0.338369   0.141994   -0.311178\n",
       "2015-11-24  0.024169  -0.271903   0.120846   -0.308157\n",
       "2015-11-25  0.011799  -0.274336   0.088496   -0.330383\n",
       "2015-11-27 -0.014577  -0.349854   0.142857   -0.364431\n",
       "2015-11-30 -0.050296  -0.372781   0.136095   -0.346154\n",
       "2015-12-01 -0.021807  -0.317757   0.155763   -0.308411\n",
       "2015-12-02 -0.019108  -0.305732   0.057325   -0.299363\n",
       "2015-12-03 -0.025974  -0.262987   0.100649   -0.295455\n",
       "2015-12-04  0.010000  -0.260000   0.050000   -0.266667\n",
       "2015-12-07 -0.009901  -0.270627   0.049505   -0.270627\n",
       "2015-12-08 -0.026667  -0.206667   0.063333   -0.260000\n",
       "2015-12-09  0.003425  -0.212329   0.027397   -0.250000\n",
       "2015-12-10 -0.047782  -0.215017   0.061433   -0.242321\n",
       "2015-12-11  0.028674  -0.182796   0.103943   -0.204301\n",
       "2015-12-14  0.045296  -0.233449   0.128920   -0.240418\n",
       "2015-12-15  0.046667  -0.263333   0.073333   -0.253333\n",
       "2015-12-16 -0.050955  -0.299363  -0.028662   -0.296178\n",
       "2015-12-17 -0.010067  -0.305369   0.050336   -0.261745\n",
       "2015-12-18 -0.193220  -0.318644   0.064407   -0.244068\n",
       "2015-12-21 -0.063025   0.121849   0.327731   -0.063025\n",
       "2015-12-22  0.125561   0.228700   0.376682   -0.017937\n",
       "2015-12-23 -0.003984   0.075697   0.227092   -0.131474\n",
       "2015-12-24  0.004000   0.156000   0.144000   -0.148000\n",
       "2015-12-28 -0.003984   0.207171   0.167331   -0.159363\n",
       "2015-12-29 -0.004000   0.308000   0.076000   -0.176000\n",
       "2015-12-30 -0.024096   0.269076   0.128514   -0.180723\n",
       "2015-12-31 -0.004115   0.390947   0.152263   -0.168724\n",
       "\n",
       "[1510 rows x 4 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
